{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* **6. Preview Triangles (Part B)**\n",
        "\n",
        "Until this point we have only worked with past data. Now lets get a visual of what we have done so far."
      ],
      "metadata": {
        "_uuid": "fbc53c7bd5b1d6e590c350fd67c6589c0c616660",
        "id": "jB9gcnce2KBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.0**\tDefine General Plot Functions"
      ],
      "metadata": {
        "_uuid": "c80be8e7b388f3ac165ba34f7692cb3cf67a14a8",
        "id": "0wZmzFg72KBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Claims Data - Single Plot\"\"\"\n",
        "def SinglePlotPartialClaims(DataFrameName, InsuredYearColumn, LagYearColumn, ValueColumn):\n",
        "    import matplotlib.pyplot as plt\n",
        "    \"\"\"Create New df\"\"\"\n",
        "    Filtered_NewColumnNames = [\"Insured_Year\",\"Year_Only_Lag\",\"ClaimAmt\"]\n",
        "    Filtered_df = pd.DataFrame(DataFrameName[[InsuredYearColumn, LagYearColumn, ValueColumn]])\n",
        "    Filtered_df.columns = Filtered_NewColumnNames\n",
        "    \"\"\"Unique Insured Years List\"\"\"\n",
        "    InsuredYr_List = list(DataFrameName[InsuredYearColumn].unique())\n",
        "    \"\"\"Unique Lag Years List\"\"\"\n",
        "    LagYr_List = list(DataFrameName[LagYearColumn].unique())\n",
        "    \"\"\"Color List\"\"\"\n",
        "    ALL_Colors = ['r','b','g','y','k', 'c', 'm', 'saddlebrown', 'pink', 'lawngreen']         \n",
        "    Color_List = ALL_Colors[:len(InsuredYr_List)]\n",
        "    \"\"\"LineStyle List\"\"\"\n",
        "    ALL_LineStyle = ['-', '--', '-.', ':','-','-','-','-','-','-','-','-','-']\n",
        "    LineStyle_List = ALL_LineStyle[:len(InsuredYr_List)]\n",
        "    \"\"\"MarkerStyle List\"\"\"# First 4x empty \n",
        "    ALL_Markers = ['','','','','^','.','o','*', '+', '1', '2', '3', '4']\n",
        "    Marker_List = ALL_Markers[:len(InsuredYr_List)]\n",
        "    \"\"\"Loop Plot\"\"\"\n",
        "    for row_A in range(0,len(InsuredYr_List)):\n",
        "        plt.figure(2, figsize=(10,5))\n",
        "        Year_i = InsuredYr_List[row_A]\n",
        "        SubFiltered_df = Filtered_df.loc[Filtered_df['Insured_Year'].isin([Year_i])]\n",
        "        plt.plot(SubFiltered_df['Year_Only_Lag'], SubFiltered_df['ClaimAmt'], \n",
        "                 label=str(Year_i), linestyle='-', color=Color_List[row_A])\n",
        "    \"\"\"Plot Attributes\"\"\"    \n",
        "    plt.xlabel('Developement Year')\n",
        "    plt.ylabel('Claims Value')\n",
        "    plt.title('Single Plot Partial Claims Data')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "_uuid": "cacf09d0e5f238058afff715da79a73c2e1c4611",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "o5xVtlv02KBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Claims Data - Sub Plot\"\"\"\n",
        "def SubPlotPartialClaims(DataFrameName, InsuredYearColumn, LagYearColumn, ValueColumn):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from matplotlib import rcParams\n",
        "    \"\"\"Create New df\"\"\"\n",
        "    Filtered_NewColumnNames = [\"Insured_Year\",\"Year_Only_Lag\",\"ClaimAmt\"]\n",
        "    Filtered_df = pd.DataFrame(DataFrameName[[InsuredYearColumn, LagYearColumn, ValueColumn]])\n",
        "    Filtered_df.columns = Filtered_NewColumnNames\n",
        "    \"\"\"Unique Insured Years List\"\"\"\n",
        "    InsuredYr_List = list(DataFrameName[InsuredYearColumn].unique())\n",
        "    \"\"\"Unique Lag Years List\"\"\"\n",
        "    LagYr_List = list(DataFrameName[LagYearColumn].unique())\n",
        "    \"\"\"Color List\"\"\"\n",
        "    ALL_Colors = ['r','b','g','y','k', 'c', 'm', 'saddlebrown', 'pink', 'lawngreen']         \n",
        "    Color_List = ALL_Colors[:len(InsuredYr_List)]\n",
        "    \"\"\"LineStyle List\"\"\"\n",
        "    ALL_LineStyle = ['-', '--', '-.', ':','-','-','-','-','-','-','-','-','-']\n",
        "    LineStyle_List = ALL_LineStyle[:len(InsuredYr_List)]\n",
        "    \"\"\"MarkerStyle List\"\"\"# First 4x empty \n",
        "    ALL_Markers = ['','','','','^','.','o','*', '+', '1', '2', '3', '4']\n",
        "    Marker_List = ALL_Markers[:len(InsuredYr_List)]\n",
        "    \"\"\"Plot Attributes\"\"\"\n",
        "    fig = plt.figure(2, figsize=(10,14))\n",
        "    plt.xticks([]) # remove initial blank plot default ticks\n",
        "    plt.yticks([]) # remove initial blank plot default ticks\n",
        "    plt.title('Sub Plot Partial Claims Data')\n",
        "    rcParams['axes.titlepad'] = 70 # position title\n",
        "    plt.box(on=None) # Remove boundary line\n",
        "    \"\"\"Loop Plot\"\"\"\n",
        "    i=0\n",
        "    for row_A in range(0,len(InsuredYr_List)):\n",
        "        ax = fig.add_subplot(5, 2, 1+i)\n",
        "        Year_i = InsuredYr_List[row_A]\n",
        "        SubFiltered_df = Filtered_df.loc[Filtered_df['Insured_Year'].isin([Year_i])]\n",
        "        plt.plot(SubFiltered_df['Year_Only_Lag'], SubFiltered_df['ClaimAmt'], \n",
        "                 label=str(Year_i), marker='o', linestyle='-', color=Color_List[row_A])\n",
        "        plt.xticks(np.arange(0, (YearEndCap-YearStartCap), step=1))\n",
        "        plt.legend()\n",
        "        i += 1\n",
        "        \"\"\"Plot Attributes\"\"\"\n",
        "        plt.xlabel('Developement Year')\n",
        "        plt.ylabel('Claims Value')\n",
        "    \n",
        "    fig.tight_layout() # set size\n",
        "    plt.show()"
      ],
      "metadata": {
        "_uuid": "5e22f7e992a5863a4ef96c92844c3697daa95dc9",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "mxAbsEEr2KBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Loss Development Ratios\"\"\"\n",
        "def SinglePlotLDF(DataFrameName, Columns):\n",
        "    import matplotlib.pyplot as  plt\n",
        "    \"\"\"Create New df\"\"\"\n",
        "    Filtered_df = pd.DataFrame(DataFrameName[Columns])    \n",
        "    \"\"\"Lag Years\"\"\"\n",
        "    LagYears_List = list(range(0, len(DataFrameName)))\n",
        "    \"\"\"Color List\"\"\"\n",
        "    ALL_Colors = ['r','b','g','y','k', 'c', 'm', 'saddlebrown', 'pink', 'lawngreen']         \n",
        "    Color_List = ALL_Colors[:len(Columns)]\n",
        "    \"\"\"Loop Plot\"\"\"\n",
        "    plt.figure(2, figsize=(10,5))\n",
        "    for row_A in range(0,len(Columns)):\n",
        "        Column_i = Columns[row_A]\n",
        "        plt.plot(LagYears_List, Filtered_df[Column_i], label=str(Column_i), linestyle='-', color=Color_List[row_A])\n",
        "        plt.legend()         \n",
        "    \"\"\"Plot Attributes\"\"\"    \n",
        "    plt.xlabel('Developement Year')\n",
        "    plt.ylabel('Ratio')\n",
        "    plt.title('Loss Development Factors')\n",
        "    plt.show()"
      ],
      "metadata": {
        "_uuid": "b02cd73ea7717215fdf9da6d076da09c03616bb0",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "cF0F7vo92KBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.1**\tIncremental Amount\n",
        "        "
      ],
      "metadata": {
        "_uuid": "68d844a721c4aa796fd04d424c3371b562768c77",
        "id": "mpHB-MjX2KBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inflated Incremental"
      ],
      "metadata": {
        "_uuid": "dc86054f8b361c732d3033fd9514f13cbebc4f01",
        "id": "CMH7DeLJ2KBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Incremental Claims Amount\n",
        "# Inflated\n",
        "py_triangle_inflated = pd.pivot_table(py_data, index=[\"Insured_Year\"], columns=[\"Year_Only_Lag\"], values=[\"Inflated_Claims_Amount\"])\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats, integrate\n",
        "sns.distplot(py_data['Inflated_Claims_Amount'], kde=False, fit=stats.lognorm) # norm, pareto, loggamma, gompertz\n",
        "plt.show()\n",
        "display(py_triangle_inflated)"
      ],
      "metadata": {
        "_uuid": "40fa6da5f796a7bf370b53bdace44f82a2ce036c",
        "trusted": true,
        "id": "t79vigUW2KBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-Inflated Incremental"
      ],
      "metadata": {
        "_uuid": "05a9a712345c9762057c298d8a3a453abbef80da",
        "id": "HnZz4nRa2KBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Incremental Claims Amount\n",
        "# Non-Inflated\n",
        "py_triangle = pd.pivot_table(py_data, index=[\"Insured_Year\"], columns=[\"Year_Only_Lag\"], values=[\"Claims_Amount\"])\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats, integrate\n",
        "sns.distplot(py_data['Claims_Amount'], kde=False, fit=stats.lognorm) # norm, pareto, loggamma, gompertz\n",
        "plt.show()\n",
        "display(py_triangle)"
      ],
      "metadata": {
        "_uuid": "3b06176a2e77a2722ba86507a1bbaeeae2bb5cdb",
        "trusted": true,
        "id": "MFF-4Zsd2KBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.2**\tCumulative Amounts"
      ],
      "metadata": {
        "_uuid": "7351141bb6561916dc9168ceec3e6819f005021b",
        "id": "6C8IIvXh2KBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inflated Cumulative"
      ],
      "metadata": {
        "_uuid": "5d3eac1e0629fa63870f74593aa27d3394860cdf",
        "id": "syvVD9Yg2KBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cumulative Claims Amount\n",
        "# Inflated\n",
        "py_triangle_cum_inflated = pd.pivot_table(py_data, index=[\"Insured_Year\"], columns=[\"Year_Only_Lag\"], values=[\"Inflated_cumsum\"])\n",
        "SinglePlotPartialClaims(DataFrameName=py_data, InsuredYearColumn='Insured_Year', LagYearColumn='Year_Only_Lag', ValueColumn='Inflated_cumsum')\n",
        "SubPlotPartialClaims(DataFrameName=py_data, InsuredYearColumn='Insured_Year', LagYearColumn='Year_Only_Lag', ValueColumn='Inflated_cumsum')\n",
        "display(py_triangle_cum_inflated)"
      ],
      "metadata": {
        "_uuid": "978625035490e1d7e990cf99ee7d79db5048aed7",
        "trusted": true,
        "id": "72EBl8Oe2KBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-Inflated Cumulative"
      ],
      "metadata": {
        "_uuid": "7d5e2c9ed3a791f40c279e39c8d93f979a9c1a62",
        "id": "0sT0Zo2D2KBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cumulative Claims Amount\n",
        "# Non-Inflated\n",
        "py_triangle_cum = pd.pivot_table(py_data, index=[\"Insured_Year\"], columns=[\"Year_Only_Lag\"], values=[\"cumsum\"])\n",
        "SinglePlotPartialClaims(DataFrameName=py_data, InsuredYearColumn='Insured_Year', LagYearColumn='Year_Only_Lag', ValueColumn='cumsum')\n",
        "SubPlotPartialClaims(DataFrameName=py_data, InsuredYearColumn='Insured_Year', LagYearColumn='Year_Only_Lag', ValueColumn='cumsum')\n",
        "display(py_triangle_cum)"
      ],
      "metadata": {
        "_uuid": "261bd3a9e79e0b1dcc96a4a95c9395210afb3b6b",
        "trusted": true,
        "id": "pdLcN0zp2KBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.3**\tIndividual Loss Development Factors"
      ],
      "metadata": {
        "_uuid": "314c60c97085b46f90640a3318396dc721e998c8",
        "id": "yjY5iBSL2KBP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inflated LDF"
      ],
      "metadata": {
        "_uuid": "a1f93373d2e7a023dad5d205c7d28cbb9f278694",
        "id": "c0VkD_g_2KBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Individual Loss Development factors\n",
        "# Inflated\n",
        "py_InflatedLossDF_triangle = pd.pivot_table(py_data, index=[\"Insured_Year\"], columns=[\"Year_Only_Lag\"], values=[\"Inflated_LossDF\"])\n",
        "SinglePlotPartialClaims(DataFrameName=py_data, InsuredYearColumn='Insured_Year', LagYearColumn='Year_Only_Lag', ValueColumn='Inflated_LossDF')\n",
        "SubPlotPartialClaims(DataFrameName=py_data, InsuredYearColumn='Insured_Year', LagYearColumn='Year_Only_Lag', ValueColumn='Inflated_LossDF')\n",
        "display(py_InflatedLossDF_triangle)"
      ],
      "metadata": {
        "_uuid": "e9327a73ea8c778d5ecf92eee265ffb18df9993a",
        "trusted": true,
        "id": "mPlLWTwL2KBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-Inflated LDF"
      ],
      "metadata": {
        "_uuid": "ad3ff63e7b6fd04a3a79b937c9f3c27b3d8163c0",
        "id": "2ms9WrX02KBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Individual Loss Development factors\n",
        "# Non-Inflated\n",
        "py_LossDF_triangle = pd.pivot_table(py_data, index=[\"Insured_Year\"], columns=[\"Year_Only_Lag\"], values=[\"LossDF\"])\n",
        "SinglePlotPartialClaims(DataFrameName=py_data, InsuredYearColumn='Insured_Year', LagYearColumn='Year_Only_Lag', ValueColumn='LossDF')\n",
        "SubPlotPartialClaims(DataFrameName=py_data, InsuredYearColumn='Insured_Year', LagYearColumn='Year_Only_Lag', ValueColumn='LossDF')\n",
        "display(py_LossDF_triangle)"
      ],
      "metadata": {
        "_uuid": "7b3ac10b8aa3775bd762862965d77253f68dd078",
        "trusted": true,
        "id": "qMFE6ENM2KBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **7. Calculations (Part B)**"
      ],
      "metadata": {
        "_uuid": "bc5faa1a12ddccee6c21e40374fa7fea662fe661",
        "id": "0jq6VoG32KBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.1**\tEstablish Predicted_df\n",
        "\n",
        "We will first create a temporary dummy data-frame \"temp_df\" containing all the years and lag years that are within our data range for analysis only for referencing purposes. \n",
        "\n"
      ],
      "metadata": {
        "_uuid": "ea6b72ba8bcb111cc4c81b7a9ab767df8648b661",
        "id": "FWhQufvq2KBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Temp Df of Predicted Years & LagYears rates\n",
        "columns_3 = ['InsuredYear', 'PredictedYear_Only_Lag',\n",
        "             'Previous_cumsum', 'Predicted_cumsum', 'Predicted_Incremental',\n",
        "             'Previous_Inflated_cumsum', 'Predicted_Inflated_cumsum', 'Predicted_Inflated_Incremental']\n",
        "Temp_df = pd.DataFrame(columns=columns_3)\n",
        "# +1 due to 31 Dec 2017 (also not a Bday) & +1 due to range exlusion of last value cap\n",
        "InsuredYr = list(range(YearStartCap + 1, YearEndCap + 1, 1))  # [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018]\n",
        "Temp_df['InsuredYear'] = InsuredYr\n",
        "Lags = list(range(0, YearEndCap - YearStartCap, 1))  # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "Temp_df['PredictedYear_Only_Lag'] = Lags\n",
        "\n",
        "# Establish Predicted data-frame\n",
        "Predicted_df = pd.DataFrame(columns=columns_3)"
      ],
      "metadata": {
        "_uuid": "00ee19b3101f2d8760e6e045c66826f499e3a565",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "O6tmGYsL2KBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.2**\tCoordinates (InsuredYear by LagYr) of predicted cells\n",
        "\n",
        "We will now move on to create the actual data-frame of the corresponding predicted insured years and lag years named as \"Predicted_df\". In other words, it is simply the combination of both the \"Insured_Years\" and \"Lag Years\" for all the NaNs that we have in the claims triangle seen before. *Unhide to view output\n",
        "\n",
        "Code Explanation-\n",
        "\n",
        "The code in short executes 2 nested loops to compare each \"Transaction Year\" (or \"Insured_Years\" plus \"Lag Year\") against the year-end-cap. Subsequently, impute the corresponding \"Insured_Years\" and \"Predicted Lag Years\". This will then act as the coordinates for the NaNs which we will use later as references for imputing our predictions.\n",
        "\n",
        "The first loop iterates through each \"InsuredYear\" column in the \"Temp_df\" data-frame to establish the \"InsuredYear\".\n",
        "\n",
        "From here, for each \"InsuredYear\" we will now start a second loop to iterate through the \"Lag Years\" and derive the \"P_yr\" (or also \"Transaction Year\").\n",
        "\n",
        "Now we will set a condition, where if the \"P_yr\" exceeds the year-end-cap we will impute that \"InsuredYear\" and \"Lag Year\" combination. Reason being because it falls beyond our past data range hence it is a predicted year. Intuitively, just the opposite of what was done in calculating the individual LDFs.\n",
        "\n",
        "Not meeting this condition, we will do nothing. Do also note the i=0 and i += 1 is for indexing purposes. 0 as python data-frames defaults via a 0 index at outset and +1 to move to the next row after imputing."
      ],
      "metadata": {
        "_uuid": "5bf5b616923117e70798e080dc3aa8f0438a0916",
        "id": "4G2wvNhx2KBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Coordinates of predicted Insured Years & Lag Years\n",
        "x = 1 # Do nothing\n",
        "i = 0 # For loop impute indexing\n",
        "for row in range(0, len(Temp_df['InsuredYear'])):\n",
        "    BaseYr = Temp_df.loc[row, 'InsuredYear']\n",
        "    for lag in range(0, len(Temp_df['PredictedYear_Only_Lag'])):\n",
        "        LagYr = Temp_df.loc[lag, 'PredictedYear_Only_Lag']\n",
        "        P_yr = BaseYr + Temp_df.loc[lag, 'PredictedYear_Only_Lag']\n",
        "        if P_yr > YearEndCap:\n",
        "\n",
        "            Predicted_df.loc[i, 'InsuredYear'] = BaseYr\n",
        "            Predicted_df.loc[i, 'PredictedYear_Only_Lag'] = LagYr\n",
        "            i += 1\n",
        "        else:\n",
        "            x = x\n",
        "\n",
        "print(Predicted_df[['InsuredYear', 'PredictedYear_Only_Lag']])"
      ],
      "metadata": {
        "_uuid": "c2acc3d7362a1666d0ff4d2e38b8590fdb7500fe",
        "_kg_hide-output": true,
        "trusted": true,
        "id": "ZnhzUr7A2KBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.3**\tImpute latest Cumulative Amounts available (as a base point for multiplying by LDF)\n",
        "\n",
        "The reason for this is because we need a base point for multiplying by our LDFs and predicting future cumulative claim amounts later. Rather than referencing separatly, we will simply do a look-up and impute accordingly. It neatens the process. *Unhide to view output\n",
        "\n",
        "Code Explanation-\n",
        "\n",
        "In short, the code loops through the \"Insured year\" and \"Lag year\" columns in \"Predicted_df\" that we derived earlier and uses these two references as look-up references against the \"py_data\" (containing past data) to find and impute the corresponding latest cumulative amounts available for that respective insured year.\n",
        "\n",
        "The loop and first 3 code lines establishes the \"Insured year\", \"Lag year\" and \"PredYr\" (\"Insured year\" + \"Lag year\") for each respective loop iteration while in the \"Predicted_df\" DataFrame.\n",
        "\n",
        "We then set 3 levels of 'If' conditionals to determine the latest cumulative sum.\n",
        "\n",
        "In chronological order-\n",
        "\n",
        "First condition; if the \"Insured year\" is equivalent to the year-end-cap, there is only one previous cumulative sum (which is the value at the lowest bottom point of a claim triangle). Hence, we will only output that.\n",
        "\n",
        "Second condition; if the predicted year \"PredYr\" exceeds the year-end-cap or if the look-up reference (via the same \"Insured year\" and \"Lag year\" minus one) for the previous cumulative sum renders none, we will keep the same insured year but replace the \"Lag year\" minus one formulae. Instead take the \"Maximum Lag year\" (the lag year of the latest cumulative claim amount available in that insured year) for that insured year as reference for the cumulative amount look-up.\n",
        "\n",
        "To put it contextually, if you refer to the above PART-5 Raw Preliminary view of Claims Triangle it is the \"Year_Only_Lag\" numbers just before a NaN. For \"Insured Year\"-2017 it would be \"Year_Only_Lag\"-0, for \"Insured Year\"-2016 it would be \"Year_Only_Lag\"-1.... etc\n",
        "\n",
        "Third condition; the residual of which does not fulfil the above two conditions uses this. Where we will simply execute the cumulative sum look-up references via the same \"Insured year\" and \"Lag year\" minus one as a reference.\n",
        "\n",
        "Finally, we will impute the latest cumulative sum in the column \"Previous_Inflated_cumsum\" of that respective row iteration in the loop within the \"Predicted_df\" data-frame.\n"
      ],
      "metadata": {
        "_uuid": "8289263fbc701befefb3a4b55d747ee702bdd255",
        "id": "q3IUCOgK2KBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute latest cumulative amounts available\n",
        "# Inflated\n",
        "for row in range(0, len(Predicted_df)):\n",
        "    Base = Predicted_df.loc[row, 'InsuredYear']\n",
        "    Lag = Predicted_df.loc[row, 'PredictedYear_Only_Lag']\n",
        "    PredYr = Base + Lag\n",
        "\n",
        "    if Base == YearEndCap:\n",
        "        PrevInflatedCumSum = py_data.loc[(py_data['Insured_Year'] == Base), 'Inflated_cumsum'].values[0]\n",
        "\n",
        "    else:\n",
        "        if PredYr > YearEndCap or len(py_data.loc[(py_data['Insured_Year'] == Base) & (py_data['Year_Only_Lag'] == Lag - 1), 'Inflated_cumsum']) == 0:\n",
        "            MaxLag = py_data.loc[(py_data['Insured_Year'] == Base), 'Year_Only_Lag'].max()\n",
        "            PrevInflatedCumSum = py_data.loc[(py_data['Insured_Year'] == Base) & (py_data['Year_Only_Lag'] == MaxLag), 'Inflated_cumsum'].values[0]\n",
        "\n",
        "        else:\n",
        "            PrevInflatedCumSum = py_data.loc[(py_data['Insured_Year'] == Base) & (py_data['Year_Only_Lag'] == Lag - 1), 'Inflated_cumsum'].values[0]\n",
        "\n",
        "    Predicted_df.loc[row, 'Previous_Inflated_cumsum'] = PrevInflatedCumSum\n",
        "\n",
        "print(Predicted_df['Previous_Inflated_cumsum'])"
      ],
      "metadata": {
        "_uuid": "0867b09bb3e6f76a92bbb0e1fd3cc74968d4c3e4",
        "_kg_hide-output": true,
        "trusted": true,
        "id": "Vq1J_hv52KBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute latest cumulative amounts available\n",
        "# Non-Inflated\n",
        "for row in range(0, len(Predicted_df)):\n",
        "    Base = Predicted_df.loc[row, 'InsuredYear']\n",
        "    Lag = Predicted_df.loc[row, 'PredictedYear_Only_Lag']\n",
        "    PredYr = Base + Lag\n",
        "\n",
        "    if Base == YearEndCap:\n",
        "        PrevCumSum = py_data.loc[(py_data['Insured_Year'] == Base), 'cumsum'].values[0]\n",
        "\n",
        "    else:\n",
        "        if PredYr > YearEndCap or len(\n",
        "                py_data.loc[(py_data['Insured_Year'] == Base) & (py_data['Year_Only_Lag'] == Lag - 1), 'cumsum']) == 0:\n",
        "            MaxLag = py_data.loc[(py_data['Insured_Year'] == Base), 'Year_Only_Lag'].max()\n",
        "            PrevCumSum = py_data.loc[(py_data['Insured_Year'] == Base) & (py_data['Year_Only_Lag'] == MaxLag), 'cumsum'].values[0]\n",
        "\n",
        "        else:\n",
        "            PrevCumSum = py_data.loc[(py_data['Insured_Year'] == Base) & (py_data['Year_Only_Lag'] == Lag - 1), 'cumsum'].values[0]\n",
        "\n",
        "    Predicted_df.loc[row, 'Previous_cumsum'] = PrevCumSum\n",
        "    \n",
        "print(Predicted_df['Previous_cumsum'])"
      ],
      "metadata": {
        "_uuid": "4e5a6b22b637b3bb303603c0ceadbb8260b97407",
        "_kg_hide-output": true,
        "trusted": true,
        "id": "qCfdWH1z2KBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.4**\tSimpleMeanLoss & Volume Weighted & Last 5/3 years & Selected LDF\n",
        "\n",
        "Now with the individual LDFs calculated earlier in *Chapter 5.6* we will now derive the average-lag year-to-lag-year LDFs. "
      ],
      "metadata": {
        "_uuid": "7fa5e41dcd6a581aaf4c651b2f879123a1884f35",
        "id": "GFXCltkr2KBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first establish the initial data-frame columns and corresponding year lags for each average LDFs to reference against when calculating from the individual LDFs."
      ],
      "metadata": {
        "_uuid": "23ee01a8d8c020cb657a5638eea26bfeb2499ce4",
        "id": "_q7EzKzn2KBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Establish averaged-year-to-year LDF\n",
        "columns_4 = ['Year_Only_Lag',\n",
        "             'SimpleMeanLossDF', 'VolWtdLossDF',\n",
        "             'CumToUlt_SimpleMeanLossDF', 'CumToUlt_VolWtdLossDF',\n",
        "             'SimpleMeanLossDF_5year', 'VolWtdLossDF_5year',\n",
        "             'SimpleMeanLossDF_3year', 'VolWtdLossDF_3year',\n",
        "             'SelectLossDF'\n",
        "             'Inflated_SimpleMeanLossDF', 'Inflated_VolWtdLossDF',\n",
        "             'Inflated_CumToUlt_SimpleMeanLossDF', 'Inflated_CumToUlt_VolWtdLossDF',\n",
        "             'Inflated_SimpleMeanLossDF_5year', 'Inflated_VolWtdLossDF_5year',\n",
        "             'Inflated_SimpleMeanLossDF_3year', 'Inflated_VolWtdLossDF_3year',\n",
        "             'Inflated_SelectLossDF']\n",
        "LossDF_df = pd.DataFrame(columns=columns_4)\n",
        "Lags = list(range(0, YearEndCap-YearStartCap, 1))\n",
        "LossDF_df['Year_Only_Lag'] = Lags\n",
        "display(LossDF_df)"
      ],
      "metadata": {
        "_uuid": "8902c2fe2078415295f0e06dda87996540c4bf0c",
        "trusted": true,
        "id": "hkKi8klY2KBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Explanation-\n",
        "\n",
        "The code loops though each \"Lag Years\" (\"Year_Only_Lag\" column) in the \"LossDF_df\" data-frame to reference the required lag year. Subsequently, for each \"Lag Year\" executes the simple mean and volume weight LDF calculations below.\n",
        "\n",
        "Simple Mean - Looks up all the LDFs having that required \"Lag Year\" reference and takes the average. However, excluding the last LDF as that would be the LDF for moving into a year outside our data range. In other words, a predicted year.\n",
        "\n",
        "Volume Weighted - Looks up all the cumulative sums having that required lag year and also the subsequent next lag year (required lag year plus 1 year) and takes the sum. However, for that required year it excludes the last cumulative sum to ensure equitable quantity of summing components. Just as in the simple mean calculation.\n",
        "\n",
        "Finally, impute and +1 to move to the next row for the proceeding loop to impute accordingly."
      ],
      "metadata": {
        "_uuid": "1fca3d8d1cd86a19dac008a14ca38505e6e997f6",
        "id": "BTEa-9kR2KBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inflated All Year Average LDFs"
      ],
      "metadata": {
        "_uuid": "11a2f1961047e60ed6f0cefca3df75fb06a41c7e",
        "id": "IIGdZ0z12KBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inflated\n",
        "i=0\n",
        "for lag in range(0, len(Temp_df['PredictedYear_Only_Lag'])):\n",
        "    lagyr = Temp_df.loc[lag, 'PredictedYear_Only_Lag']\n",
        "    # Simple Mean\n",
        "    # due to 0 input so exlude last value\n",
        "    SimpleMeanLossDF = py_data.loc[py_data['Year_Only_Lag'] == lagyr, 'Inflated_LossDF'][:-1].mean()\n",
        "    LossDF_df.loc[i, 'Inflated_SimpleMeanLossDF'] = SimpleMeanLossDF\n",
        "    # Volume Weighted\n",
        "    Deno = py_data.loc[py_data['Year_Only_Lag'] == (lagyr + 1), 'Inflated_cumsum'].sum()\n",
        "    Neum = py_data.loc[py_data['Year_Only_Lag'] == lagyr, 'Inflated_cumsum'][:-1].sum()\n",
        "    VolWtdLossDF = Deno / Neum\n",
        "    LossDF_df.loc[i, 'Inflated_VolWtdLossDF'] = VolWtdLossDF\n",
        "    i += 1\n",
        "\n",
        "# [::-1] to flip or invert the row order\n",
        "LossDF_df['Inflated_CumToUlt_SimpleMeanLossDF']=LossDF_df['Inflated_SimpleMeanLossDF'][::-1].cumprod()\n",
        "LossDF_df['Inflated_CumToUlt_VolWtdLossDF']=LossDF_df['Inflated_VolWtdLossDF'][::-1].cumprod()\n",
        "\n",
        "SinglePlotLDF(DataFrameName=LossDF_df, Columns=['Inflated_SimpleMeanLossDF', 'Inflated_VolWtdLossDF'])\n",
        "SinglePlotLDF(DataFrameName=LossDF_df, Columns=['Inflated_CumToUlt_SimpleMeanLossDF', 'Inflated_CumToUlt_VolWtdLossDF'])\n",
        "display(LossDF_df[['Inflated_SimpleMeanLossDF', 'Inflated_VolWtdLossDF', 'Inflated_CumToUlt_SimpleMeanLossDF', 'Inflated_CumToUlt_VolWtdLossDF']])"
      ],
      "metadata": {
        "_uuid": "e690d85c791a6e1a6adf2ec396c844acabcac6de",
        "trusted": true,
        "id": "1sb5gkwj2KBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-Inflated All Year Average LDFs"
      ],
      "metadata": {
        "_uuid": "2fa3df933ac1174d7f136a4691d72c32f677bde6",
        "id": "Wl1HLwUe2KBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-Inflated\n",
        "i=0\n",
        "for lag in range(0, len(Temp_df['PredictedYear_Only_Lag'])):\n",
        "    lagyr = Temp_df.loc[lag, 'PredictedYear_Only_Lag']\n",
        "    # Simple Mean\n",
        "    # due to 0 input so exlude last value\n",
        "    SimpleMeanLossDF = py_data.loc[py_data['Year_Only_Lag'] == lagyr, 'LossDF'][:-1].mean()\n",
        "    LossDF_df.loc[i, 'SimpleMeanLossDF'] = SimpleMeanLossDF\n",
        "    # Volume Weighted\n",
        "    Deno = py_data.loc[py_data['Year_Only_Lag'] == (lagyr + 1), 'cumsum'].sum()\n",
        "    Neum = py_data.loc[py_data['Year_Only_Lag'] == lagyr, 'cumsum'][:-1].sum()\n",
        "    VolWtdLossDF = Deno / Neum\n",
        "    LossDF_df.loc[i, 'VolWtdLossDF'] = VolWtdLossDF\n",
        "    i += 1\n",
        "\n",
        "# [::-1] to flip or invert the row order\n",
        "LossDF_df['CumToUlt_SimpleMeanLossDF']=LossDF_df['SimpleMeanLossDF'][::-1].cumprod()\n",
        "LossDF_df['CumToUlt_VolWtdLossDF']=LossDF_df['VolWtdLossDF'][::-1].cumprod()\n",
        "\n",
        "SinglePlotLDF(DataFrameName=LossDF_df, Columns=['SimpleMeanLossDF', 'VolWtdLossDF'])\n",
        "SinglePlotLDF(DataFrameName=LossDF_df, Columns=['CumToUlt_SimpleMeanLossDF', 'CumToUlt_VolWtdLossDF'])\n",
        "display(LossDF_df[['SimpleMeanLossDF', 'VolWtdLossDF', 'CumToUlt_SimpleMeanLossDF', 'CumToUlt_VolWtdLossDF']])"
      ],
      "metadata": {
        "_uuid": "f753abfe3d12857a7a5df9c9bc355cd225989981",
        "trusted": true,
        "id": "ezWkW63Y2KBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last 5 & 3 year averages\n",
        "\n",
        "The 5/3 Year Averages are just as we did earlier. The only difference is that now rather than the '-1' to exclude the final entry, we replace that with the number of years we want. In this case, I declared them as Year_A for 5 year and Year_B for 3 year averages."
      ],
      "metadata": {
        "_uuid": "47da3ae7ba859c89d9a708f6dd6264e6574a9d28",
        "id": "gXYfFZ2J2KBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inflated 5 & 3 year Average LDFs"
      ],
      "metadata": {
        "_uuid": "a33cabb94047e1b6dcef912946952df817880f89",
        "id": "0DeToE9Y2KBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inflated\n",
        "i=0\n",
        "for lag in range(0, len(Temp_df['PredictedYear_Only_Lag'])):\n",
        "    lagyr = Temp_df.loc[lag, 'PredictedYear_Only_Lag']\n",
        "    # Simple Mean\n",
        "    Year_A = 5   # 5 Year\n",
        "    SimpleMeanLossDF_Ayear = py_data.loc[py_data['Year_Only_Lag'] == lagyr, 'Inflated_LossDF'][:Year_A].mean()\n",
        "    LossDF_df.loc[i, 'Inflated_SimpleMeanLossDF_5year'] = SimpleMeanLossDF_Ayear\n",
        "    Year_B = 3   # 3 Year\n",
        "    SimpleMeanLossDF_Byear = py_data.loc[py_data['Year_Only_Lag'] == lagyr, 'Inflated_LossDF'][:Year_B].mean()\n",
        "    LossDF_df.loc[i, 'Inflated_SimpleMeanLossDF_3year'] = SimpleMeanLossDF_Byear\n",
        "    # Volume Weighted\n",
        "    Deno_A = py_data.loc[py_data['Year_Only_Lag'] == (lagyr + 1), 'Inflated_cumsum'][:Year_A].sum()\n",
        "    Neum_A = py_data.loc[py_data['Year_Only_Lag'] == lagyr, 'Inflated_cumsum'][:Year_A].sum()\n",
        "    VolWtdLossDF_A = Deno_A / Neum_A\n",
        "    LossDF_df.loc[i, 'Inflated_VolWtdLossDF_5year'] = VolWtdLossDF_A\n",
        "    Deno_B = py_data.loc[py_data['Year_Only_Lag'] == (lagyr + 1), 'Inflated_cumsum'][:Year_B].sum()\n",
        "    Neum_B = py_data.loc[py_data['Year_Only_Lag'] == lagyr, 'Inflated_cumsum'][:Year_B].sum()\n",
        "    VolWtdLossDF_B = Deno_B / Neum_B\n",
        "    LossDF_df.loc[i, 'Inflated_VolWtdLossDF_3year'] = VolWtdLossDF_B\n",
        "    i += 1\n",
        "\n",
        "SinglePlotLDF(DataFrameName=LossDF_df, Columns=['Inflated_SimpleMeanLossDF_5year', 'Inflated_VolWtdLossDF_5year'])\n",
        "SinglePlotLDF(DataFrameName=LossDF_df, Columns=['Inflated_SimpleMeanLossDF_3year', 'Inflated_VolWtdLossDF_3year'])    \n",
        "display(LossDF_df[['Inflated_SimpleMeanLossDF_5year', 'Inflated_VolWtdLossDF_5year', 'Inflated_SimpleMeanLossDF_3year', 'Inflated_VolWtdLossDF_3year']])"
      ],
      "metadata": {
        "_uuid": "cd95303a65dbc4a755066083380a4a1f493a944b",
        "trusted": true,
        "id": "WNxF6HNr2KBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-Inflated 5 & 3 year Average LDFs"
      ],
      "metadata": {
        "_uuid": "20908b5df08acc3cbbef794d1cd0225b052136d7",
        "id": "9hu9C6YJ2KBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Non Inflated\n",
        "i=0\n",
        "for lag in range(0, len(Temp_df['PredictedYear_Only_Lag'])):\n",
        "    lagyr = Temp_df.loc[lag, 'PredictedYear_Only_Lag']\n",
        "    # Simple Mean\n",
        "    Year_A = 5   # 5 Year\n",
        "    SimpleMeanLossDF_Ayear = py_data.loc[py_data['Year_Only_Lag'] == lagyr, 'Inflated_LossDF'][:Year_A].mean()\n",
        "    LossDF_df.loc[i, 'SimpleMeanLossDF_5year'] = SimpleMeanLossDF_Ayear\n",
        "    Year_B = 3   # 3 Year\n",
        "    SimpleMeanLossDF_Byear = py_data.loc[py_data['Year_Only_Lag'] == lagyr, 'Inflated_LossDF'][:Year_B].mean()\n",
        "    LossDF_df.loc[i, 'SimpleMeanLossDF_3year'] = SimpleMeanLossDF_Byear\n",
        "    # Volume Weighted\n",
        "    Deno_A = py_data.loc[py_data['Year_Only_Lag'] == (lagyr + 1), 'Inflated_cumsum'][:Year_A].sum()\n",
        "    Neum_A = py_data.loc[py_data['Year_Only_Lag'] == lagyr, 'Inflated_cumsum'][:Year_A].sum()\n",
        "    VolWtdLossDF_A = Deno_A / Neum_A\n",
        "    LossDF_df.loc[i, 'VolWtdLossDF_5year'] = VolWtdLossDF_A\n",
        "    Deno_B = py_data.loc[py_data['Year_Only_Lag'] == (lagyr + 1), 'Inflated_cumsum'][:Year_B].sum()\n",
        "    Neum_B = py_data.loc[py_data['Year_Only_Lag'] == lagyr, 'Inflated_cumsum'][:Year_B].sum()\n",
        "    VolWtdLossDF_B = Deno_B / Neum_B\n",
        "    LossDF_df.loc[i, 'VolWtdLossDF_3year'] = VolWtdLossDF_B\n",
        "    i += 1\n",
        "\n",
        "SinglePlotLDF(DataFrameName=LossDF_df, Columns=['SimpleMeanLossDF_5year', 'VolWtdLossDF_5year'])\n",
        "SinglePlotLDF(DataFrameName=LossDF_df, Columns=['SimpleMeanLossDF_3year', 'VolWtdLossDF_3year'])\n",
        "display(LossDF_df[['SimpleMeanLossDF_5year', 'VolWtdLossDF_5year', 'SimpleMeanLossDF_3year', 'VolWtdLossDF_3year']])"
      ],
      "metadata": {
        "_uuid": "28bd57c81b7acbb6598e32d4cc54656272b931f4",
        "trusted": true,
        "id": "xVEwem5X2KBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selected LDF\n",
        "\n",
        "In real world scenarios, actuaries will analyze the consistency in LDFs calculated above. Some reasons include abnormally large claims may distort the LDF trend, legislative reasons to exclude a specific number of years in the LDF averages etc..\n",
        "\n",
        "In this case we will simply use the fully all year averaged LDFs since it is the smoothest amongst the choices."
      ],
      "metadata": {
        "_uuid": "53af52a0757f45ab5cfa8cd5d1bc199d060b378c",
        "id": "2FRj80at2KBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LossDF_df['Inflated_SelectLossDF'] = LossDF_df['Inflated_VolWtdLossDF']\n",
        "LossDF_df['SelectLossDF'] = LossDF_df['VolWtdLossDF']"
      ],
      "metadata": {
        "_uuid": "eee37005705432e5dedb710b3f018c6f82bb7717",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "JHQN2awu2KBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.5**\tPredicted Cumulative Amounts = Uplift previous Cumulative Amounts by LDF\n",
        "\n",
        "Now with a selected LDF we will proceed to use historical claim trends to predict future claim trends! Pretty much self explanatory here. We simply apply the respective LDF to each past cumulative claim to derive the future cumulative claim. On the assumption trends will follow suit. *Unhide to view output\n",
        "\n",
        "Code Explanation-\n",
        "\n",
        "As mentioned before we are predicting using the latest cumulative amount as the baseline. Thus, we will set them equal first for easy reference.\n",
        "\n",
        "In short, the code iterates through the \"Predicted_df\" to determine the year range to apply the LDF for prediction, and correspondingly references the LDF aligning to that year range from the \"LossDF_df\" to predict the amount.\n",
        "\n",
        "The code uses 2 nested loops. The first loop in the \"Predicted_df\" is used to establish the combination of the \"Insured year\" and \"Lag year\" that the predicted year belongs to. It is also used to derive the \"Maximum Lag year\". Exactly, what we did in PART-7 Impute latest cumulative amounts.\n",
        "\n",
        "The second loop in the \"LossDF_df\" data-frame is used to iterate over the various \"Lag years\" to reference the averaged-by-lag-year LDFs we calculated above to predict the respective cumulative amounts. Whilst under the second loop, we set 2 conditionals -\n",
        "\n",
        "First condition: If this ongoing second loop iteration reaches the last \"Lag year\" we will do nothing. The reason being is that the final lag year is the ultimate \"Lag year\", hence no LDF is available.\n",
        "\n",
        "Second condition: If this second loop iteration's \"Lag year\" reaches a equilibrium with the maximum \"Lag year\" for that \"Insured year\" from that ongoing first loop iteration we will only then proceed with the predicting calculation. In other words, when the \"Lag year\" of the \"Predicted_df\" and the \"LossDF_df\" are equal.\n",
        "\n",
        "The calculation simply takes the product of all the averaged-by-lag-year LDFs falling within inclusively of the maximum lag year and the predicted lag year minus one range (both of which established from that ongoing first loop iteration) and multiplies that into the latest cumulative sum to attain the predicted cumulative sum.\n",
        "\n",
        "Not fulfilling either condition we will do nothing.\n"
      ],
      "metadata": {
        "_uuid": "9e24306a2ef042fdb09cb6f1a4bb8b4a2461185d",
        "id": "UgwTkNzr2KBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Cumulative Claim Amounts\n",
        "# Inflated\n",
        "# Set Equal for easy reference\n",
        "Predicted_df['Predicted_Inflated_cumsum'] = Predicted_df['Previous_Inflated_cumsum']\n",
        "lagyearlimit = (YearEndCap - YearStartCap) - 1\n",
        "x = 1  # Do nothing\n",
        "for row in range(0, len(Predicted_df)):\n",
        "    PredLagYr = Predicted_df.loc[row, 'PredictedYear_Only_Lag']\n",
        "    BaseInsuredYr = Predicted_df.loc[row, 'InsuredYear']\n",
        "    MaxLagYr = py_data.loc[(py_data['Insured_Year'] == BaseInsuredYr), 'Year_Only_Lag'].max()\n",
        "    for r in range(0, len(LossDF_df)):\n",
        "        if (LossDF_df.loc[r, 'Year_Only_Lag'] == lagyearlimit):\n",
        "            x = x  # To avoid NaN\n",
        "        elif (LossDF_df.loc[r, 'Year_Only_Lag'] == MaxLagYr):\n",
        "            # LDF multiplication\n",
        "            LDF = LossDF_df.loc[(LossDF_df['Year_Only_Lag'] >= MaxLagYr) & (LossDF_df['Year_Only_Lag'] <= (PredLagYr - 1)), 'Inflated_SelectLossDF'].prod()\n",
        "            Predicted_df.loc[row, 'Predicted_Inflated_cumsum'] = Predicted_df.loc[row, 'Predicted_Inflated_cumsum'] * LDF\n",
        "        else:\n",
        "            x = x  # Do nothing\n",
        "            \n",
        "print(Predicted_df['Predicted_Inflated_cumsum'])"
      ],
      "metadata": {
        "_uuid": "a25fad244c1e75204b1a7b6c0ff364948f28f318",
        "_kg_hide-output": true,
        "trusted": true,
        "id": "ayju47Th2KBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Cumulative Claim Amounts\n",
        "# Non-Inflated\n",
        "# Set Equal for easy reference\n",
        "Predicted_df['Predicted_cumsum'] = Predicted_df['Previous_cumsum']\n",
        "lagyearlimit = (YearEndCap - YearStartCap) - 1\n",
        "x = 1  # Do nothing\n",
        "for row in range(0, len(Predicted_df)):\n",
        "    PredLagYr = Predicted_df.loc[row, 'PredictedYear_Only_Lag']\n",
        "    BaseInsuredYr = Predicted_df.loc[row, 'InsuredYear']\n",
        "    MaxLagYr = py_data.loc[(py_data['Insured_Year'] == BaseInsuredYr), 'Year_Only_Lag'].max()\n",
        "    for r in range(0, len(LossDF_df)):\n",
        "        if (LossDF_df.loc[r, 'Year_Only_Lag'] == lagyearlimit):\n",
        "            x = x  # To avoid NaN\n",
        "        elif (LossDF_df.loc[r, 'Year_Only_Lag'] == MaxLagYr):\n",
        "            # LDF multiplication\n",
        "            LDF = LossDF_df.loc[(LossDF_df['Year_Only_Lag'] >= MaxLagYr) & (LossDF_df['Year_Only_Lag'] <= (PredLagYr - 1)), 'SelectLossDF'].prod()\n",
        "            Predicted_df.loc[row, 'Predicted_cumsum'] = Predicted_df.loc[row, 'Predicted_cumsum'] * LDF\n",
        "        else:\n",
        "            x = x  # Do nothing\n",
        "\n",
        "print(Predicted_df['Predicted_cumsum'])"
      ],
      "metadata": {
        "_uuid": "9a6e4fea8daee2fa3dceef03cdf818c5adc18ed3",
        "_kg_hide-output": true,
        "trusted": true,
        "id": "Q6Tmi5km2KBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.6**\tData-type adjustments (int & float)\n",
        "\n",
        "This is just a intermediate step to ensure consistent computational data-types as so many data manipulations were made before."
      ],
      "metadata": {
        "_uuid": "c3704faa0f76955a4d178b200809bc447d2742a0",
        "id": "iX54Iy8V2KBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data-type adjustments\n",
        "# Years\n",
        "Predicted_df[['InsuredYear','PredictedYear_Only_Lag']]=Predicted_df[['InsuredYear','PredictedYear_Only_Lag']].astype(int)\n",
        "# Amounts\n",
        "Predicted_df[['Predicted_cumsum','Previous_cumsum']]=Predicted_df[['Predicted_cumsum','Previous_cumsum']].astype(float)\n",
        "Predicted_df[['Predicted_Inflated_cumsum','Previous_Inflated_cumsum']]=Predicted_df[['Predicted_Inflated_cumsum','Previous_Inflated_cumsum']].astype(float)"
      ],
      "metadata": {
        "_uuid": "35f0b9c5e26e448e70f1a56641c910daec71d092",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "-0155CBv2KBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.7**\tPredicted Incremental Amount\n",
        "\n",
        "**Do note that the Insured year column now starts from 2009 not 2008 as in the past claims data \"py_data\" data-frame**\n",
        "\n",
        "With the predicted cumulative amount derive earlier, we will now derive the incremental amount. Reason being we need to use the incremental amount to project future inflation (just as we did for past inflation).\n",
        "\n",
        "Code Explanation-\n",
        "\n",
        "The code simply loops through both data-frames \"Predicted_df\" (predicted data) and \"py_data\" (past data) and looks up the respective current and previous cumulative amount based on \"Insured Year\" and \"Lag Year\" references. Subsequently, calculates the difference which is then the incremental amount.\n",
        "\n",
        "Just as before we will loop the predicted data-frame and first establish the \"Insured year\", \"Lag year\" and \"Current predicted cumulative amount\" (belonging to the current loop iteration). After which using the \"Insured year\" and \"Lag year\" minus one combination as references to look-up the previous cumulative amount.\n",
        "\n",
        "The code then sets 2 conditionals -\n",
        "\n",
        "First condition: If we are not able to look up the respective previous cumulative values in the predicted data-frame \"Predicted_df\", we instead search in the past cumulative values data-frame \"py_data\". This specifically required for those amounts falling on the 'steps' of a claim triangle.\n",
        "\n",
        "Second condition: Here we are simply searching the predicted data-frame \"Predicted_df\"."
      ],
      "metadata": {
        "_uuid": "f5432e0445e0385a604d93c8e6558ad1758f74aa",
        "id": "As-5S5yX2KBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Incremental Amount\n",
        "# Inflated\n",
        "for row in range(0, len(Predicted_df)):\n",
        "    InsurYr = Predicted_df.loc[row, 'InsuredYear']\n",
        "    LagYr = Predicted_df.loc[row, 'PredictedYear_Only_Lag']\n",
        "    CurrCum = Predicted_df.loc[row, 'Predicted_Inflated_cumsum']\n",
        "    # For which we can't look up in Predicted_df\n",
        "    if len(Predicted_df.loc[(Predicted_df['InsuredYear'] == InsurYr) & (Predicted_df['PredictedYear_Only_Lag'] == LagYr - 1), 'Predicted_Inflated_cumsum']) == 0:\n",
        "        PrevCum = py_data.loc[(py_data['Insured_Year'] == InsurYr) & (py_data['Year_Only_Lag'] == LagYr - 1), 'Inflated_cumsum'].values[0]\n",
        "    # For which we can look up in Predicted_df\n",
        "    else:\n",
        "        PrevCum = Predicted_df.loc[(Predicted_df['InsuredYear'] == InsurYr) & (Predicted_df['PredictedYear_Only_Lag'] == LagYr - 1), 'Predicted_Inflated_cumsum'].values[0]\n",
        "\n",
        "    Predicted_df.loc[row, 'Predicted_Inflated_Incremental'] = (CurrCum - PrevCum)\n",
        "\n",
        "Predicted_df[['Predicted_Inflated_Incremental']] = Predicted_df[['Predicted_Inflated_Incremental']].astype(float)\n",
        "PredictedInflatedIncrementalTriangle = pd.pivot_table(Predicted_df, index=[\"InsuredYear\"],columns=[\"PredictedYear_Only_Lag\"],values=[\"Predicted_Inflated_Incremental\"])\n",
        "\n",
        "# print(PredictedInflatedIncrementalTriangle)\n",
        "display(PredictedInflatedIncrementalTriangle)"
      ],
      "metadata": {
        "_uuid": "2a84759ec19e853189166554934477e7ad4478ba",
        "trusted": true,
        "id": "Urjc-3UQ2KBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Incremental Amount\n",
        "# Non-Inflated\n",
        "for row in range(0, len(Predicted_df)):\n",
        "    InsurYr = Predicted_df.loc[row, 'InsuredYear']\n",
        "    LagYr = Predicted_df.loc[row, 'PredictedYear_Only_Lag']\n",
        "    CurrCum = Predicted_df.loc[row, 'Predicted_cumsum']\n",
        "\n",
        "    if len(Predicted_df.loc[(Predicted_df['InsuredYear'] == InsurYr) & (Predicted_df['PredictedYear_Only_Lag'] == LagYr - 1), 'Predicted_cumsum']) == 0:\n",
        "        PrevCum = py_data.loc[(py_data['Insured_Year'] == InsurYr) & (py_data['Year_Only_Lag'] == LagYr - 1), 'cumsum'].values[0]\n",
        "    else:\n",
        "        PrevCum = Predicted_df.loc[(Predicted_df['InsuredYear'] == InsurYr) & (Predicted_df['PredictedYear_Only_Lag'] == LagYr - 1), 'Predicted_cumsum'].values[0]\n",
        "\n",
        "    Predicted_df.loc[row, 'Predicted_Incremental'] = CurrCum - PrevCum\n",
        "\n",
        "Predicted_df[['Predicted_Incremental']] = Predicted_df[['Predicted_Incremental']].astype(float)\n",
        "PredictedIncrementalTriangle = pd.pivot_table(Predicted_df, index=[\"InsuredYear\"], columns=[\"PredictedYear_Only_Lag\"],values=[\"Predicted_Incremental\"])\n",
        "\n",
        "# print(PredictedIncrementalTriangle)\n",
        "display(PredictedIncrementalTriangle)"
      ],
      "metadata": {
        "_uuid": "7ce7da4b5e514d476db5b4dd30f4855ef0fff3af",
        "trusted": true,
        "id": "msKSg4rr2KBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.8**\tProject (Future Inflation) Predicted Incremental Amount\n",
        "\n",
        "Now to project for future inflation. *Unhide to view output\n",
        "\n",
        "Code Explanation-\n",
        "\n",
        "This is rather straightforward as well. First we determine the future inflation index (\"FutureInflation\") via look-up using the year-end-cap plus one as reference.\n",
        "\n",
        "Now just as before, we simply first equate the future uplifted incremental claims amount derived above to the existing nominal valued as at year-end-cap for easy reference.\n",
        "\n",
        "Likewise, we also first loop to establish the \"Insured Year\", \"Lag Year\" and \"Current incremental amount\". We then uplift by taking the \"Current incremental amount\" multiplied by the \"FutureInflation\" and the \"Lag Year\" being the index exponent."
      ],
      "metadata": {
        "_uuid": "60d8b71911ee97a82abf88b5c402939dbee64f69",
        "id": "FjOpwPpW2KBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Project (Future Inflation) Predicted Incremental Amount\n",
        "# Inflated\n",
        "FutureInflation = Inflation_df.loc[(Inflation_df['Year'] == (YearEndCap + 1)), 'CumPastInflation'].values[0]\n",
        "\n",
        "Predicted_df['FutureUplifted_Predicted_Inflated_Incremental'] = Predicted_df['Predicted_Inflated_Incremental']\n",
        "for row in range(0, len(Predicted_df)):\n",
        "    InsurYr = Predicted_df.loc[row, 'InsuredYear']\n",
        "    LagYr = Predicted_df.loc[row, 'PredictedYear_Only_Lag']\n",
        "    CurrIncremAmt = Predicted_df.loc[row, 'Predicted_Inflated_Incremental']\n",
        "    Predicted_df.loc[row, 'FutureUplifted_Predicted_Inflated_Incremental'] = CurrIncremAmt * (FutureInflation ** LagYr)\n",
        "    \n",
        "print(Predicted_df['FutureUplifted_Predicted_Inflated_Incremental'])"
      ],
      "metadata": {
        "_uuid": "d0aae957283bff23325deb12b0ae61a5a72a9dce",
        "_kg_hide-output": true,
        "trusted": true,
        "id": "sJG9QBP42KBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Project (Future Inflation) Predicted Incremental Amount\n",
        "# Non-Inflated\n",
        "# Set equal for easy reference\n",
        "Predicted_df['FutureUplifted_Predicted_Incremental'] = Predicted_df['Predicted_Incremental']\n",
        "FutureInflation = Inflation_df.loc[(Inflation_df['Year'] == (YearEndCap + 1)), 'CumPastInflation'].values[0]\n",
        "\n",
        "for row in range(0, len(Predicted_df)):\n",
        "    InsurYr = Predicted_df.loc[row, 'InsuredYear']\n",
        "    LagYr = Predicted_df.loc[row, 'PredictedYear_Only_Lag']\n",
        "    CurrIncremAmt = Predicted_df.loc[row, 'Predicted_Incremental']\n",
        "\n",
        "    Predicted_df.loc[row, 'FutureUplifted_Predicted_Incremental'] = CurrIncremAmt * (FutureInflation ** LagYr)\n",
        "    \n",
        "print(Predicted_df['FutureUplifted_Predicted_Incremental'])"
      ],
      "metadata": {
        "_uuid": "02dd72d565f905d546f41a008bb59d6fb04ef576",
        "_kg_hide-output": true,
        "trusted": true,
        "id": "gr16FuV52KBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **8. Preview Predictions (Part C)**\n",
        "\n",
        "Now lets view what we have done so far!"
      ],
      "metadata": {
        "_uuid": "dfd99fdd5b6649994e49b0288bda3159295039e5",
        "id": "Huh4e_5O2KBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.1**\tIncremental Amount  "
      ],
      "metadata": {
        "_uuid": "7f2f5e26ec4408d10acb9a793ef3333cff96948e",
        "id": "kdrdBMyA2KBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Incremental\n",
        "# Non-Inflated\n",
        "PredictedTriangle = pd.pivot_table(Predicted_df, index=[\"InsuredYear\"], columns=[\"PredictedYear_Only_Lag\"], values=[\"FutureUplifted_Predicted_Incremental\"])\n",
        "# Inflated\n",
        "PredictedInflatedTriangle = pd.pivot_table(Predicted_df, index=[\"InsuredYear\"], columns=[\"PredictedYear_Only_Lag\"], values=[\"FutureUplifted_Predicted_Inflated_Incremental\"])"
      ],
      "metadata": {
        "_uuid": "705f125721dc47bf98b5d256b19f49b7dba1200d",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "CbWaa8aT2KBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-Inflated Incremental"
      ],
      "metadata": {
        "_uuid": "6187ffb8055e791ff28fd5caaa8c2548868aa8e7",
        "id": "YuQec1wR2KBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SinglePlotPartialClaims(DataFrameName=Predicted_df, InsuredYearColumn='InsuredYear', LagYearColumn='PredictedYear_Only_Lag', ValueColumn='FutureUplifted_Predicted_Incremental')\n",
        "SubPlotPartialClaims(DataFrameName=Predicted_df, InsuredYearColumn='InsuredYear', LagYearColumn='PredictedYear_Only_Lag', ValueColumn='FutureUplifted_Predicted_Incremental')\n",
        "display(PredictedTriangle)"
      ],
      "metadata": {
        "_uuid": "4a70674bcff99e002e073e9118c16036e69b382d",
        "trusted": true,
        "id": "-YsKbWXH2KBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inflated Incremental"
      ],
      "metadata": {
        "_uuid": "f8d590a2ff0b7cf2fecfb2a5182bbd2ae03d0698",
        "id": "sZ9zvbL42KBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SinglePlotPartialClaims(DataFrameName=Predicted_df, InsuredYearColumn='InsuredYear', LagYearColumn='PredictedYear_Only_Lag', ValueColumn='FutureUplifted_Predicted_Inflated_Incremental')\n",
        "SubPlotPartialClaims(DataFrameName=Predicted_df, InsuredYearColumn='InsuredYear', LagYearColumn='PredictedYear_Only_Lag', ValueColumn='FutureUplifted_Predicted_Inflated_Incremental')\n",
        "display(PredictedInflatedTriangle)"
      ],
      "metadata": {
        "_uuid": "df2adf0fe720b9e7941699b42c1b1e8e0ea77cda",
        "trusted": true,
        "id": "ESRc8BGc2KBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.2**\tCumulative Amounts"
      ],
      "metadata": {
        "_uuid": "21731d62e05151dfcd75a355afa707667ece05de",
        "id": "ZtEgFxhF2KBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cumulative\n",
        "# Non-Inflated\n",
        "PredictedCumTriangle = pd.pivot_table(Predicted_df, index=[\"InsuredYear\"], columns=[\"PredictedYear_Only_Lag\"], values=[\"Predicted_cumsum\"])\n",
        "# Inflated\n",
        "PredictedInflatedCumTriangle = pd.pivot_table(Predicted_df, index=[\"InsuredYear\"], columns=[\"PredictedYear_Only_Lag\"], values=[\"Predicted_Inflated_cumsum\"])"
      ],
      "metadata": {
        "_uuid": "a1fdb541d2402f3512873077748812f76041d8a8",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "z41BhFn52KBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-Inflated Cumulative"
      ],
      "metadata": {
        "_uuid": "47055aa32d9ee5d2bd0424e0b8e1ae85119e9fe1",
        "id": "JpZknNVy2KBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SinglePlotPartialClaims(DataFrameName=Predicted_df, InsuredYearColumn='InsuredYear', LagYearColumn='PredictedYear_Only_Lag', ValueColumn='Predicted_cumsum')\n",
        "SubPlotPartialClaims(DataFrameName=Predicted_df, InsuredYearColumn='InsuredYear', LagYearColumn='PredictedYear_Only_Lag', ValueColumn='Predicted_cumsum')\n",
        "display(PredictedCumTriangle)"
      ],
      "metadata": {
        "_uuid": "e218d3abbc5a0f6068b346fad20fd69a243e933e",
        "trusted": true,
        "id": "w92sI3Vz2KBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inflated Cumulative"
      ],
      "metadata": {
        "_uuid": "52c7a479c0774ad201c8c3d210e9d553ac91d6cb",
        "id": "KI2lGKE92KBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SinglePlotPartialClaims(DataFrameName=Predicted_df, InsuredYearColumn='InsuredYear', LagYearColumn='PredictedYear_Only_Lag', ValueColumn='Predicted_Inflated_cumsum')\n",
        "SubPlotPartialClaims(DataFrameName=Predicted_df, InsuredYearColumn='InsuredYear', LagYearColumn='PredictedYear_Only_Lag', ValueColumn='Predicted_Inflated_cumsum')\n",
        "display(PredictedInflatedCumTriangle)"
      ],
      "metadata": {
        "_uuid": "208c04bb81f0c237f217821c2b438be3974cf6a8",
        "trusted": true,
        "id": "ngTdBZZh2KBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.**\t**Full Triangle**"
      ],
      "metadata": {
        "_uuid": "7050419a17005c810d44a051d9128b392b752724",
        "id": "YRq59Wct2KBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.0** Define General Plot Functions"
      ],
      "metadata": {
        "_uuid": "107b821866b9a24a8f769e655093cfb95a354cd4",
        "id": "7QzNCf_T2KBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SinglePlotFullClaims(PastDataFrameName, PastInsuredYearColumn, PastLagYearColumn, PastValueColumn, \n",
        "                   FutureDataFrameName, FutureInsuredYearColumn, FutureLagYearColumn, FutureValueColumn):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from matplotlib import rcParams\n",
        "    # https://stackoverflow.com/questions/16419670/increase-distance-between-title-and-plot-in-matplolib\n",
        "    \"\"\"Create New df\"\"\"\n",
        "    Filtered_NewColumnNames = [\"Insured_Year\",\"Year_Only_Lag\",\"ClaimAmt\"]\n",
        "    # Past\n",
        "    Past_Filtered_df = pd.DataFrame(PastDataFrameName[[PastInsuredYearColumn, PastLagYearColumn, PastValueColumn]])\n",
        "    Past_Filtered_df.columns = Filtered_NewColumnNames\n",
        "    # Future\n",
        "    Future_Filtered_df = pd.DataFrame(FutureDataFrameName[[FutureInsuredYearColumn, FutureLagYearColumn, FutureValueColumn]])\n",
        "    Future_Filtered_df.columns = Filtered_NewColumnNames    \n",
        "    \"\"\"Unique Insured Years List\"\"\"\n",
        "    # Past\n",
        "    Past_InsuredYr_List = list(PastDataFrameName[PastInsuredYearColumn].unique())\n",
        "    # Future\n",
        "    Future_InsuredYr_List = list(FutureDataFrameName[FutureInsuredYearColumn].unique())\n",
        "    \"\"\"Unique Lag Years List\"\"\"\n",
        "    # Past\n",
        "    Past_LagYr_List = list(PastDataFrameName[PastLagYearColumn].unique())\n",
        "    # Future\n",
        "    Future_LagYr_List = list(FutureDataFrameName[FutureLagYearColumn].unique())\n",
        "    \"\"\"Color List\"\"\"\n",
        "    ALL_Colors = ['r','b','g','y','k', 'c', 'm', 'saddlebrown', 'pink', 'lawngreen']         \n",
        "    Past_Color_List = ALL_Colors[:len(Past_InsuredYr_List)]\n",
        "    Future_Color_List = ALL_Colors[:len(Future_InsuredYr_List)]\n",
        "    \"\"\"Plotting\"\"\"\n",
        "    fig = plt.figure(2, figsize=(8,12))\n",
        "    plt.title('Single Plot Full Claims Data')\n",
        "    \"\"\"Full Loop Plot\"\"\"\n",
        "    Full_Filtered_df = pd.concat([Past_Filtered_df, Future_Filtered_df])\n",
        "    for row_A in range(0,len(Past_InsuredYr_List)):\n",
        "        Year_i = Past_InsuredYr_List[row_A]\n",
        "        Full_SubFiltered_df = Full_Filtered_df.loc[Full_Filtered_df['Insured_Year'].isin([Year_i])]\n",
        "        plt.plot(Full_SubFiltered_df['Year_Only_Lag'], Full_SubFiltered_df['ClaimAmt'], \n",
        "                 label=('Predicted %d' % Year_i), linestyle='--', color=Past_Color_List[row_A])\n",
        "        plt.legend()\n",
        "        plt.xlabel('Developement Year')\n",
        "        plt.ylabel('Claims Value')    \n",
        "    \"\"\"Past Loop Plot\"\"\"\n",
        "    for row_A in range(0,len(Past_InsuredYr_List)):\n",
        "        Year_i = Past_InsuredYr_List[row_A]\n",
        "        Past_SubFiltered_df = Past_Filtered_df.loc[Past_Filtered_df['Insured_Year'].isin([Year_i])]\n",
        "        plt.plot(Past_SubFiltered_df['Year_Only_Lag'], Past_SubFiltered_df['ClaimAmt'], \n",
        "                 label=('Historical %d' % Year_i), linestyle='-', color=Past_Color_List[row_A], marker='o')\n",
        "        plt.legend()\n",
        "    #\"\"\"Future Loop Plot\"\"\"\n",
        "    #for row_B in range(0,len(Future_InsuredYr_List)):\n",
        "    #    Year_i = Future_InsuredYr_List[row_B]\n",
        "    #    Future_SubFiltered_df = Future_Filtered_df.loc[Future_Filtered_df['Insured_Year'].isin([Year_i])]\n",
        "    #    plt.plot(Future_SubFiltered_df['Year_Only_Lag'], Future_SubFiltered_df['ClaimAmt'], \n",
        "    #             label=str(Year_i), linestyle='--', color=Future_Color_List[row_B])    \n",
        "    \n",
        "    \"\"\"Plot Attributes\"\"\"    \n",
        "    plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_uuid": "2d510797ffcb0c6e101f1036c281fac1c965f081",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "9QYBkRAj2KBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SubPlotFullClaims(PastDataFrameName, PastInsuredYearColumn, PastLagYearColumn, PastValueColumn, \n",
        "                   FutureDataFrameName, FutureInsuredYearColumn, FutureLagYearColumn, FutureValueColumn):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from matplotlib import rcParams\n",
        "    # https://stackoverflow.com/questions/16419670/increase-distance-between-title-and-plot-in-matplolib\n",
        "    \"\"\"Create New df\"\"\"\n",
        "    Filtered_NewColumnNames = [\"Insured_Year\",\"Year_Only_Lag\",\"ClaimAmt\"]\n",
        "    # Past\n",
        "    Past_Filtered_df = pd.DataFrame(PastDataFrameName[[PastInsuredYearColumn, PastLagYearColumn, PastValueColumn]])\n",
        "    Past_Filtered_df.columns = Filtered_NewColumnNames\n",
        "    # Future\n",
        "    Future_Filtered_df = pd.DataFrame(FutureDataFrameName[[FutureInsuredYearColumn, FutureLagYearColumn, FutureValueColumn]])\n",
        "    Future_Filtered_df.columns = Filtered_NewColumnNames    \n",
        "    \"\"\"Unique Insured Years List\"\"\"\n",
        "    # Past\n",
        "    Past_InsuredYr_List = list(PastDataFrameName[PastInsuredYearColumn].unique())\n",
        "    # Future\n",
        "    Future_InsuredYr_List = list(FutureDataFrameName[FutureInsuredYearColumn].unique())\n",
        "    \"\"\"Unique Lag Years List\"\"\"\n",
        "    # Past\n",
        "    Past_LagYr_List = list(PastDataFrameName[PastLagYearColumn].unique())\n",
        "    # Future\n",
        "    Future_LagYr_List = list(FutureDataFrameName[FutureLagYearColumn].unique())\n",
        "    \"\"\"Color List\"\"\"\n",
        "    ALL_Colors = ['r','b','g','y','k', 'c', 'm', 'saddlebrown', 'pink', 'lawngreen']         \n",
        "    Past_Color_List = ALL_Colors[:len(Past_InsuredYr_List)]\n",
        "    Future_Color_List = ALL_Colors[:len(Future_InsuredYr_List)]\n",
        "    \"\"\"Plotting\"\"\"\n",
        "    fig = plt.figure(2, figsize=(12,16))\n",
        "    plt.xticks([]) # remove initial blank plot default ticks\n",
        "    plt.yticks([]) # remove initial blank plot default ticks\n",
        "    plt.title('Sub Plot Full Claims Data')\n",
        "    rcParams['axes.titlepad'] = 50 # position title\n",
        "    plt.box(on=None) # Remove boundary line\n",
        "    \"\"\"Full Loop Plot\"\"\"\n",
        "    Full_Filtered_df = pd.concat([Past_Filtered_df, Future_Filtered_df])\n",
        "    i=0\n",
        "    for row_A in range(0,len(Past_InsuredYr_List)):\n",
        "        ax = fig.add_subplot(5, 2, 1+i)\n",
        "        Year_i = Past_InsuredYr_List[row_A]\n",
        "        Full_SubFiltered_df = Full_Filtered_df.loc[Full_Filtered_df['Insured_Year'].isin([Year_i])]\n",
        "        plt.plot(Full_SubFiltered_df['Year_Only_Lag'], Full_SubFiltered_df['ClaimAmt'], \n",
        "                 label=('Predicted %d' % Year_i), linestyle='--', color=Past_Color_List[row_A])\n",
        "        plt.legend()\n",
        "        i += 1\n",
        "        plt.xticks(np.arange(0, (YearEndCap-YearStartCap), step=1))\n",
        "        plt.xlabel('Developement Year')\n",
        "        plt.ylabel('Claims Value') \n",
        "    \"\"\"Past Loop Plot\"\"\"\n",
        "    i=0\n",
        "    for row_A in range(0,len(Past_InsuredYr_List)):\n",
        "        ax = fig.add_subplot(5, 2, 1+i)\n",
        "        Year_i = Past_InsuredYr_List[row_A]\n",
        "        Past_SubFiltered_df = Past_Filtered_df.loc[Past_Filtered_df['Insured_Year'].isin([Year_i])]\n",
        "        plt.plot(Past_SubFiltered_df['Year_Only_Lag'], Past_SubFiltered_df['ClaimAmt'], \n",
        "                 label=('Historical %d' % Year_i), linestyle='-', color=Past_Color_List[row_A], marker='o')\n",
        "        plt.legend()\n",
        "        i += 1\n",
        "    #\"\"\"Future Loop Plot\"\"\"\n",
        "    #for row_B in range(0,len(Future_InsuredYr_List)):\n",
        "    #    Year_i = Future_InsuredYr_List[row_B]\n",
        "    #    Future_SubFiltered_df = Future_Filtered_df.loc[Future_Filtered_df['Insured_Year'].isin([Year_i])]\n",
        "    #    plt.plot(Future_SubFiltered_df['Year_Only_Lag'], Future_SubFiltered_df['ClaimAmt'], \n",
        "    #             label=str(Year_i), linestyle='--', color=Future_Color_List[row_B])    \n",
        "    \"\"\"Plot Attributes\"\"\"    \n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_uuid": "7166c3cf91ef4bf8b656431347988dfce7042198",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "lZckIVC22KBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.1 Non-Inflated Claims"
      ],
      "metadata": {
        "_uuid": "88a0d1ab1a89342e7756451a4663184f17e92f1f",
        "id": "akXtyqpq2KBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SinglePlotFullClaims(PastDataFrameName=py_data, PastInsuredYearColumn=\"Insured_Year\", PastLagYearColumn=\"Year_Only_Lag\", PastValueColumn=\"cumsum\", \n",
        "               FutureDataFrameName=Predicted_df, FutureInsuredYearColumn=\"InsuredYear\", FutureLagYearColumn=\"PredictedYear_Only_Lag\", FutureValueColumn=\"Predicted_cumsum\")"
      ],
      "metadata": {
        "_uuid": "38f6eb395bff42c61b7ef2dd82e0444f50f6276a",
        "trusted": true,
        "id": "DJUIeqi72KBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SubPlotFullClaims(PastDataFrameName=py_data, PastInsuredYearColumn=\"Insured_Year\", PastLagYearColumn=\"Year_Only_Lag\", PastValueColumn=\"cumsum\", \n",
        "               FutureDataFrameName=Predicted_df, FutureInsuredYearColumn=\"InsuredYear\", FutureLagYearColumn=\"PredictedYear_Only_Lag\", FutureValueColumn=\"Predicted_cumsum\")"
      ],
      "metadata": {
        "_uuid": "c3397b0896d643e71cb5f3da997099c5efc4743d",
        "trusted": true,
        "id": "aNk1Ydqb2KBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.2 Inflated Claims"
      ],
      "metadata": {
        "_uuid": "8e04ae3dc5f2b6df94fab35bb2fd0b4caaae994a",
        "id": "yjiV7q0c2KBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SinglePlotFullClaims(PastDataFrameName=py_data, PastInsuredYearColumn=\"Insured_Year\", PastLagYearColumn=\"Year_Only_Lag\", PastValueColumn=\"Inflated_cumsum\", \n",
        "               FutureDataFrameName=Predicted_df, FutureInsuredYearColumn=\"InsuredYear\", FutureLagYearColumn=\"PredictedYear_Only_Lag\", FutureValueColumn=\"Predicted_Inflated_cumsum\")"
      ],
      "metadata": {
        "_uuid": "4f8994ad9c6631a50870ac8f27ea69895bf9cdf4",
        "trusted": true,
        "id": "gRG8-PDN2KBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SubPlotFullClaims(PastDataFrameName=py_data, PastInsuredYearColumn=\"Insured_Year\", PastLagYearColumn=\"Year_Only_Lag\", PastValueColumn=\"Inflated_cumsum\", \n",
        "               FutureDataFrameName=Predicted_df, FutureInsuredYearColumn=\"InsuredYear\", FutureLagYearColumn=\"PredictedYear_Only_Lag\", FutureValueColumn=\"Predicted_Inflated_cumsum\")"
      ],
      "metadata": {
        "_uuid": "5d7a1564a81846b509026c2e796cd78a3b00188c",
        "trusted": true,
        "id": "LtsF8pYL2KBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **10. Reserves**\n",
        "\n",
        "Last but simplest step of all. The amount insurers need to cover their predicted claim costs, assuming past trends continue."
      ],
      "metadata": {
        "_uuid": "191ef1c03b978b127d57b2270fa56673903ce867",
        "id": "eUUAWNuu2KBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10.1** Inflated Amounts"
      ],
      "metadata": {
        "_uuid": "0996fc80fc92832cff24a062c24af7f0dbbcd216",
        "id": "rvIvwW_Z2KBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "InflatedReserves = Predicted_df['FutureUplifted_Predicted_Inflated_Incremental'].sum()\n",
        "print(InflatedReserves)"
      ],
      "metadata": {
        "_uuid": "b2e7b92d92d8364bd670eb37d9f991443a1fd6e8",
        "trusted": true,
        "id": "MBu8Xj_X2KBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10.2** Non Inflated Amounts"
      ],
      "metadata": {
        "_uuid": "b01c73557cb0e00664459a72000522e574d8fd42",
        "id": "GSJVZvxR2KBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NonInflatedReserves = Predicted_df['FutureUplifted_Predicted_Incremental'].sum()\n",
        "print(NonInflatedReserves)"
      ],
      "metadata": {
        "_uuid": "d75d2b4c599974c5f9d157de1b066516fbcdbccd",
        "trusted": true,
        "id": "YbCMvFSX2KBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PercDiff = 100*(InflatedReserves/NonInflatedReserves-1)\n",
        "print('Percentage Difference {}'.format(PercDiff))"
      ],
      "metadata": {
        "_uuid": "f06bdcf6162c7dad29dcd6ed081713d6016df446",
        "trusted": true,
        "id": "CygMMIfE2KBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "Evidently, the inflated reserves far exceed that of the non inflated reserves. Despite inflation rates falling, the fact that we uplifted the amounts is a an easy attribution to the reserve results.\n",
        "\n",
        "Do stay tuned as I plan to do some sensitivity analysis on this going forward!"
      ],
      "metadata": {
        "_uuid": "e26ee5cca0a1fd7369be7648f920614fd8363a26",
        "id": "fxjSzMYi2KBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thank you for reading till the end! Hope you now have a deeper understanding of Data Manipulation using Pandas & also IACL calculations.\n",
        "\n",
        "Cheers!"
      ],
      "metadata": {
        "_uuid": "b28d6e8a82b578a384481502346fa30e5575b2b3",
        "id": "9S9d3elB2KBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "_uuid": "7ed42afaf0e7b2b74ba95030f172a71262b95b39",
        "id": "GhfTLAmR2KBZ"
      }
    }
  ]
}